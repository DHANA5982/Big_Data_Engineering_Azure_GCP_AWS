{"cells": [{"cell_type": "markdown", "id": "f83d9eca-2ac5-499d-92e2-a09742bc0a8b", "metadata": {"tags": []}, "source": "# Olist E-Commerce Data"}, {"cell_type": "markdown", "id": "ae8aa8a5-a601-4f15-be70-f387c13df265", "metadata": {}, "source": "**Setting up Spark Environment**\n\n1\\. Deploy a spark cluster (Dataproc, EMR, HDInsight, On-Premis)\n\n2\\. Download the data from Kaggle website [Link](https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce)\n\n3\\. Bash command to direct download to HDFS \n- Make sure to create a proper directory to put downloaded and to extract files into\n- I created olist folder to download file\n```\ncurl -L -o ~/olist/brazilian-ecommerce.zip\\\n  https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce\n```\n- I created data folder inside olist to extract files\n\n```\nunzip brazilian-ecommerce.zip -d ~/olist/data/\n```\n\n4\\. Store Data in HDFS worker nodes\n- I create folder to distribute files from hadoop master node to worker nodes\n```\n!hadoop fs -put ~/olist/data/*.csv /data/olist/\n```\n    \n5\\. Use Pyspark to intract with Data\n\n"}, {"cell_type": "markdown", "id": "639cacf8-130c-4fb5-9644-b7e9607577e0", "metadata": {"tags": []}, "source": "# Data Ingestion"}, {"cell_type": "markdown", "id": "8c9ac530-a953-42ad-ba62-e66b406e9a5a", "metadata": {}, "source": "**Downloaded and extracted data in hadoop master cluster**"}, {"cell_type": "code", "execution_count": 21, "id": "149c7bec-f373-4940-89ac-0ebe746152f8", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "brazilian-ecommerce.zip  \u001b[0m\u001b[01;34mdata\u001b[0m/\n"}], "source": "ls /home/sekar_dhana8644/olist/"}, {"cell_type": "code", "execution_count": 20, "id": "16c9cf9b-4a60-439c-86aa-f3cae91ab617", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "olist_customers_dataset.csv       olist_orders_dataset.csv\nolist_geolocation_dataset.csv     olist_products_dataset.csv\nolist_order_items_dataset.csv     olist_sellers_dataset.csv\nolist_order_payments_dataset.csv  product_category_name_translation.csv\nolist_order_reviews_dataset.csv\n"}], "source": "ls /home/sekar_dhana8644/olist/data/"}, {"cell_type": "markdown", "id": "ae2352bc-7e6f-4df6-9799-0daa25218bc0", "metadata": {}, "source": "**Moved data from Hadoop master cluster to worker nodes**"}, {"cell_type": "code", "execution_count": 19, "id": "9c7c9992-27e4-4ef3-961e-41955f91f189", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 9 items\n-rw-r--r--   2 sekar_dhana8644 hadoop      8.6 M 2025-08-30 19:17 /data/olist/olist_customers_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop     58.4 M 2025-08-30 19:17 /data/olist/olist_geolocation_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop     14.7 M 2025-08-30 19:17 /data/olist/olist_order_items_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop      5.5 M 2025-08-30 19:17 /data/olist/olist_order_payments_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop     13.8 M 2025-08-30 19:17 /data/olist/olist_order_reviews_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop     16.8 M 2025-08-30 19:17 /data/olist/olist_orders_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop      2.3 M 2025-08-30 19:17 /data/olist/olist_products_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop    170.6 K 2025-08-30 19:17 /data/olist/olist_sellers_dataset.csv\n-rw-r--r--   2 sekar_dhana8644 hadoop      2.6 K 2025-08-30 19:17 /data/olist/product_category_name_translation.csv\n"}], "source": "!hadoop fs -ls -h /data/olist/"}, {"cell_type": "markdown", "id": "d49cd10c-ea5c-4748-ba33-fe459bcfdb34", "metadata": {}, "source": "# Data Exploration"}, {"cell_type": "code", "execution_count": 2, "id": "328e4792-1db2-4f79-a164-507293f002f5", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/08/31 18:17:50 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}, {"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://first-hadoop-cluster-m.us-central1-a.c.clear-wind-468921-g9.internal:42895\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f750766e750>"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('OlistDataset').getOrCreate()\n\nspark"}, {"cell_type": "code", "execution_count": 3, "id": "1b90a713-a61a-48f2-a292-9e46b7373019", "metadata": {"tags": []}, "outputs": [], "source": "hdfs_path = '/data/olist/'"}, {"cell_type": "code", "execution_count": 4, "id": "858d6577-d032-4e68-973d-9627de8ad7b9", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "customer_df = spark.read.csv(hdfs_path + 'olist_customers_dataset.csv',header=True, inferSchema=True)"}, {"cell_type": "code", "execution_count": 28, "id": "0eb0a34a-cf3c-42a7-99cb-b76abea52260", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------------------+--------------------+--------------+\n|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n+--------------------+--------------------+------------------------+--------------------+--------------+\n|06b8999e2fba1a1fb...|861eff4711a542e4b...|                   14409|              franca|            SP|\n|18955e83d337fd6b2...|290c77bc529b7ac93...|                    9790|sao bernardo do c...|            SP|\n|4e7b3e00288586ebd...|060e732b5b29e8181...|                    1151|           sao paulo|            SP|\n|b2b6027bc5c5109e5...|259dac757896d24d7...|                    8775|     mogi das cruzes|            SP|\n|4f2d8ab171c80ec83...|345ecd01c38d18a90...|                   13056|            campinas|            SP|\n+--------------------+--------------------+------------------------+--------------------+--------------+\nonly showing top 5 rows\n\n"}], "source": "customer_df.show(5)"}, {"cell_type": "code", "execution_count": 5, "id": "ffb2274c-37d5-43f9-baae-d0c900201965", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "geolocation_df = spark.read.csv(hdfs_path + 'olist_geolocation_dataset.csv',header=True, inferSchema=True)\norder_items_df = spark.read.csv(hdfs_path + 'olist_order_items_dataset.csv',header=True, inferSchema=True)\norder_payments_df = spark.read.csv(hdfs_path + 'olist_order_payments_dataset.csv',header=True, inferSchema=True)\norder_reviews_df = spark.read.csv(hdfs_path + 'olist_order_reviews_dataset.csv',header=True, inferSchema=True)\norders_df = spark.read.csv(hdfs_path + 'olist_orders_dataset.csv',header=True, inferSchema=True)\nproducts_df = spark.read.csv(hdfs_path + 'olist_products_dataset.csv',header=True, inferSchema=True)\nsellers_df = spark.read.csv(hdfs_path + 'olist_sellers_dataset.csv',header=True, inferSchema=True)\ntranslation_df = spark.read.csv(hdfs_path + 'product_category_name_translation.csv',header=True, inferSchema=True)"}, {"cell_type": "code", "execution_count": 43, "id": "b27d3e6b-4637-4777-8fb0-aa818d686e5d", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n\n"}], "source": "customer_df.printSchema()"}, {"cell_type": "code", "execution_count": 45, "id": "872565b6-8573-4887-8a63-2dc35026772d", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- order_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n\n"}], "source": "orders_df.printSchema()"}, {"cell_type": "code", "execution_count": 6, "id": "bdc9d07a-5553-422d-aac1-04354afbd788", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Customers df: 99441 rows\nOrders df: 99441 rows\nOrder Items df: 112650 rows\nOrder Payments df: 103886 rows\nOrder Reviews df: 104162 rows\nProducts df: 32951 rows\nSellers df: 3095 rows\nProduct Category Name Translation df: 71 rows\n"}], "source": "# Data Leakage or Drop\n\nprint(f'Customers df: {customer_df.count()} rows')\nprint(f'Orders df: {orders_df.count()} rows')\nprint(f'Order Items df: {order_items_df.count()} rows')\nprint(f'Order Payments df: {order_payments_df.count()} rows')\nprint(f'Order Reviews df: {order_reviews_df.count()} rows')\nprint(f'Products df: {products_df.count()} rows')\nprint(f'Sellers df: {sellers_df.count()} rows')\nprint(f'Product Category Name Translation df: {translation_df.count()} rows')"}, {"cell_type": "code", "execution_count": 9, "id": "7953eeb4-5290-47b8-8392-11285bb5dbd4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+------------------+------------------------+-------------+--------------+\n|customer_id|customer_unique_id|customer_zip_code_prefix|customer_city|customer_state|\n+-----------+------------------+------------------------+-------------+--------------+\n|          0|                 0|                       0|            0|             0|\n+-----------+------------------+------------------------+-------------+--------------+\n\n"}], "source": "# Null Values\n\nfrom pyspark.sql.functions import *\n\ncustomer_df.select([count(when(col(c).isNull(),1)).alias(c) for c in customer_df.columns]).show()"}, {"cell_type": "code", "execution_count": 7, "id": "172db74c-9e56-4ea5-a4d0-c49445a2ce7a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 42:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-----+\n|customer_id|count|\n+-----------+-----+\n+-----------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Duplicate Values\n\ncustomer_df.groupBy('customer_id').count().filter('count>1').show()"}, {"cell_type": "code", "execution_count": 10, "id": "eef2dfb0-2eb6-471e-bdf6-38341a32996d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------+-----+\n|customer_state|count|\n+--------------+-----+\n|            SP|41746|\n|            RJ|12852|\n|            MG|11635|\n|            RS| 5466|\n|            PR| 5045|\n|            SC| 3637|\n|            BA| 3380|\n|            DF| 2140|\n|            ES| 2033|\n|            GO| 2020|\n|            PE| 1652|\n|            CE| 1336|\n|            PA|  975|\n|            MT|  907|\n|            MA|  747|\n|            MS|  715|\n|            PB|  536|\n|            PI|  495|\n|            RN|  485|\n|            AL|  413|\n+--------------+-----+\nonly showing top 20 rows\n\n"}], "source": "# Customer Distribution by State\n\ncustomer_df.groupBy('customer_state').count().orderBy(col('count').desc()).show()"}, {"cell_type": "code", "execution_count": 13, "id": "44159472-0938-4b51-a89c-bd7fab57b60a", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-----+\n|       customer_city|count|\n+--------------------+-----+\n|           sao paulo|15540|\n|      rio de janeiro| 6882|\n|      belo horizonte| 2773|\n|            brasilia| 2131|\n|            curitiba| 1521|\n|            campinas| 1444|\n|        porto alegre| 1379|\n|            salvador| 1245|\n|           guarulhos| 1189|\n|sao bernardo do c...|  938|\n|             niteroi|  849|\n|         santo andre|  797|\n|              osasco|  746|\n|              santos|  713|\n|             goiania|  692|\n| sao jose dos campos|  691|\n|           fortaleza|  654|\n|            sorocaba|  633|\n|              recife|  613|\n|       florianopolis|  570|\n+--------------------+-----+\nonly showing top 20 rows\n\n"}], "source": "# Customer Distribution by City\n\ncustomer_df.groupBy('customer_city').count().orderBy('count', ascending=False).show()"}, {"cell_type": "code", "execution_count": 17, "id": "c20a63f2-bcf0-4742-8bd4-bae65023942e", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "['order_id',\n 'customer_id',\n 'order_status',\n 'order_purchase_timestamp',\n 'order_approved_at',\n 'order_delivered_carrier_date',\n 'order_delivered_customer_date',\n 'order_estimated_delivery_date']"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "orders_df.columns"}, {"cell_type": "code", "execution_count": 18, "id": "c1ec0f38-6fe5-4277-a078-43ede1c51a26", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+-----+\n|order_status|count|\n+------------+-----+\n|   delivered|96478|\n|     shipped| 1107|\n|    canceled|  625|\n| unavailable|  609|\n|    invoiced|  314|\n|  processing|  301|\n|     created|    5|\n|    approved|    2|\n+------------+-----+\n\n"}], "source": "# Order Distribution by Order Status\n\norders_df.groupBy('order_status').count().orderBy('count', ascending=False).show()"}, {"cell_type": "code", "execution_count": 35, "id": "00829931-18e9-43bf-bb1f-45e2ab1e29cb", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------------+-----------------------------+\n|            order_id|order_purchase_timestamp|order_delivered_customer_date|\n+--------------------+------------------------+-----------------------------+\n|e481f51cbdc54678b...|     2017-10-02 10:56:33|          2017-10-10 21:25:13|\n|53cdb2fc8bc7dce0b...|     2018-07-24 20:41:37|          2018-08-07 15:27:45|\n|47770eb9100c2d0c4...|     2018-08-08 08:38:49|          2018-08-17 18:06:29|\n|949d5b44dbf5de918...|     2017-11-18 19:28:06|          2017-12-02 00:28:42|\n|ad21c59c0840e6cb8...|     2018-02-13 21:18:39|          2018-02-16 18:17:02|\n+--------------------+------------------------+-----------------------------+\nonly showing top 5 rows\n\n"}], "source": "delivery_df = orders_df.select('order_id', 'order_purchase_timestamp', 'order_delivered_customer_date')\ndelivery_df.show(5)"}, {"cell_type": "code", "execution_count": 36, "id": "5f31a503-54e4-4125-af5a-11dce0ca565b", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------------+-----------------------------+-------------+\n|            order_id|order_purchase_timestamp|order_delivered_customer_date|delivery_time|\n+--------------------+------------------------+-----------------------------+-------------+\n|e481f51cbdc54678b...|     2017-10-02 10:56:33|          2017-10-10 21:25:13|            8|\n|53cdb2fc8bc7dce0b...|     2018-07-24 20:41:37|          2018-08-07 15:27:45|           14|\n|47770eb9100c2d0c4...|     2018-08-08 08:38:49|          2018-08-17 18:06:29|            9|\n|949d5b44dbf5de918...|     2017-11-18 19:28:06|          2017-12-02 00:28:42|           14|\n|ad21c59c0840e6cb8...|     2018-02-13 21:18:39|          2018-02-16 18:17:02|            3|\n+--------------------+------------------------+-----------------------------+-------------+\nonly showing top 5 rows\n\n"}], "source": "delivery_time = delivery_df.withColumn('delivery_time', datediff(col('order_delivered_customer_date'), col('order_purchase_timestamp')))\ndelivery_time.show(5)"}, {"cell_type": "code", "execution_count": 37, "id": "a7be6030-1870-431f-ab1b-4c24ef7a62d3", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------------+-----------------------------+-------------+\n|            order_id|order_purchase_timestamp|order_delivered_customer_date|delivery_time|\n+--------------------+------------------------+-----------------------------+-------------+\n|ca07593549f1816d2...|     2017-02-21 23:31:27|          2017-09-19 14:36:39|          210|\n|1b3190b2dfa9d789e...|     2018-02-23 14:57:35|          2018-09-19 23:24:07|          208|\n|440d0d17af552815d...|     2017-03-07 23:59:51|          2017-09-19 15:12:50|          196|\n|2fb597c2f772eca01...|     2017-03-08 18:09:02|          2017-09-19 14:33:17|          195|\n|285ab9426d6982034...|     2017-03-08 22:47:40|          2017-09-19 14:00:04|          195|\n+--------------------+------------------------+-----------------------------+-------------+\nonly showing top 5 rows\n\n"}], "source": "# Average Order Delivery Time\n\ndelivery_time.orderBy('delivery_time', ascending=False).show(5)"}, {"cell_type": "code", "execution_count": 32, "id": "fedb39e9-1bb4-4eb9-a269-c519de7f9daf", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "['order_id',\n 'payment_sequential',\n 'payment_type',\n 'payment_installments',\n 'payment_value']"}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": "order_payments_df.columns"}, {"cell_type": "code", "execution_count": 20, "id": "ed22fdcc-d854-4455-9271-22169d02095a", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+-----+\n|payment_type|count|\n+------------+-----+\n| credit_card|76795|\n|      boleto|19784|\n|     voucher| 5775|\n|  debit_card| 1529|\n| not_defined|    3|\n+------------+-----+\n\n"}], "source": "# Payment Distribution by Payment Method\n\norder_payments_df.groupBy('payment_type').count().orderBy('count', ascending=False).show()"}, {"cell_type": "code", "execution_count": 21, "id": "6b7e6375-552a-4e19-8d90-689163f8db0d", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "['order_id',\n 'order_item_id',\n 'product_id',\n 'seller_id',\n 'shipping_limit_date',\n 'price',\n 'freight_value']"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "order_items_df.columns"}, {"cell_type": "code", "execution_count": 26, "id": "033d0b2b-5630-4965-800f-bb52ac5610e4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------+-----+\n|          product_id|       total_sales|count|\n+--------------------+------------------+-----+\n|bb50f2e236e5eea01...|           63885.0|  195|\n|6cdd53843498f9289...| 54730.20000000005|  156|\n|d6160fb7873f18409...|48899.340000000004|   35|\n|d1c427060a0f73f6b...| 47214.51000000006|  343|\n|99a4788cb24856965...|43025.560000000085|  488|\n|3dd2a17168ec895c7...| 41082.60000000005|  274|\n|25c38557cf793876c...| 38907.32000000001|   38|\n|5f504b3a1c75b73d6...|37733.899999999994|   63|\n|53b36df67ebb7c415...| 37683.42000000001|  323|\n|aca2eb7d00ea1a7b8...| 37608.90000000007|  527|\n|e0d64dcfaa3b6db5c...|          31786.82|  194|\n|d285360f29ac7fd97...|31623.809999999983|  123|\n|7a10781637204d8d1...|           30467.5|  143|\n|f1c7f353075ce59d8...|          29997.36|  154|\n|f819f0c84a64f02d3...|29024.479999999996|   45|\n|588531f8ec37e7d5f...|28291.989999999998|   20|\n|422879e10f4668299...|26577.219999999972|  484|\n|16c4e87b98a9370a9...|           25034.0|   13|\n|5a848e4ab52fd5445...|24229.029999999962|  197|\n|a62e25e09e05e6faf...|           24051.0|  226|\n+--------------------+------------------+-----+\nonly showing top 20 rows\n\n"}], "source": "# Top products by sales amount\n\ntop_product = order_items_df.groupBy('product_id').agg(sum('price').alias('total_sales'), count('product_id').alias('count'))\ntop_product.orderBy('total_sales', ascending=False).show()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}